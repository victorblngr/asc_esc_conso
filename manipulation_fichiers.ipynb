{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9f23d7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer les bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a963da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(\n",
    "    os.getcwd(), \"points_marquants\", \"Points marquants maintenance 2024.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Filtrer les colonnes\n",
    "df = df[\n",
    "    [\n",
    "        \"DATE Début\",\n",
    "        \"HEURE Début\",\n",
    "        \"DATE Fin\",\n",
    "        \"HEURE Fin\",\n",
    "        # \"Durée indispo (j) totale\",\n",
    "        \"LIGNE\",\n",
    "        \"STATION\",\n",
    "        \"N° EQUIP.\",\n",
    "        \"COMMENTAIRE\",\n",
    "        \"Motifs\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"DATE Début\": \"date_debut_panne\",\n",
    "        \"HEURE Début\": \"heure_debut_panne\",\n",
    "        \"DATE Fin\": \"date_fin_panne\",\n",
    "        \"HEURE Fin\": \"heure_fin_panne\",\n",
    "        # \"Durée indispo (j) totale\": \"nb_jours_indispo\",\n",
    "        \"LIGNE\": \"ligne\",\n",
    "        \"STATION\": \"station\",\n",
    "        \"N° EQUIP.\": \"num_equip\",\n",
    "        \"COMMENTAIRE\": \"commentaire\",\n",
    "        \"Motifs\": \"motifs\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convertir les colonnes de date au format dd/mm/yyyy\n",
    "df[\"date_debut_panne\"] = pd.to_datetime(df[\"date_debut_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"date_fin_panne\"] = pd.to_datetime(df[\"date_fin_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "# Convertir les colonnes de temps au format HH:MM\n",
    "def convert_time_format(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        time_str = time_str.replace(\"h\", \":\").replace(\"H\", \":\")\n",
    "        if \":\" in time_str and len(time_str.split(\":\")[1]) == 0:\n",
    "            time_str += \"00\"\n",
    "    return time_str\n",
    "\n",
    "\n",
    "df[\"heure_debut_panne\"] = df[\"heure_debut_panne\"].apply(convert_time_format)\n",
    "df[\"heure_fin_panne\"] = df[\"heure_fin_panne\"].apply(convert_time_format)\n",
    "\n",
    "# Créer colonne type_equipement\n",
    "df[\"type_equipement\"] = (\n",
    "    df[\"num_equip\"].str.startswith(\"Asc\").map({True: \"ascenseur\", False: \"escalier\"})\n",
    ")\n",
    "\n",
    "# Créer une colonne annee_debut_panne\n",
    "df[\"annee_debut_panne\"] = pd.to_datetime(\n",
    "    df[\"date_debut_panne\"], format=\"%d/%m/%Y\"\n",
    ").dt.year\n",
    "\n",
    "\n",
    "# Calculer la durée d'indisponibilité en heures et jours\n",
    "def calculate_duration(row):\n",
    "    try:\n",
    "        start = pd.to_datetime(\n",
    "            f\"{row['date_debut_panne']} {row['heure_debut_panne']}\",\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "        )\n",
    "        end = pd.to_datetime(\n",
    "            f\"{row['date_fin_panne']} {row['heure_fin_panne']}\", format=\"%d/%m/%Y %H:%M\"\n",
    "        )\n",
    "        duration = (end - start).total_seconds() / 3600  # Convertir en heures\n",
    "        return duration, duration / 24  # Retourner heures et jours\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "df[[\"duree_indispo\", \"jour_indispo\"]] = df.apply(\n",
    "    calculate_duration, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Replace 'T1 ' with 'T1' in the 'ligne' column\n",
    "df[\"ligne\"] = df[\"ligne\"].str.replace(\"T1 \", \"T1\", regex=False)\n",
    "\n",
    "# Extract integers from the 'num_equip' column and create a new column 'id'\n",
    "df[\"id\"] = (\n",
    "    df[\"num_equip\"].str.extract(r\"(\\d+)\").astype(float)\n",
    ")  # Use raw string for regex\n",
    "\n",
    "df.to_csv(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_24_clean.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "df.to_excel(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_24_clean.xlsx\"),\n",
    "    index=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a552210c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VBO\\code\\asc_esc_consolide\\.conda\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(\n",
    "    os.getcwd(), \"points_marquants\", \"Points marquants maintenance Janv 2025.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(file_path, skiprows=1)\n",
    "\n",
    "# Filtrer les colonnes\n",
    "df = df[\n",
    "    [\n",
    "        \"DATE Début\",\n",
    "        \"HEURE Début\",\n",
    "        \"DATE Fin\",\n",
    "        \"HEURE Fin\",\n",
    "        # \"Durée indispo (j) totale\",\n",
    "        \"LIGNE\",\n",
    "        \"STATION\",\n",
    "        \"N° EQUIP.\",\n",
    "        \"COMMENTAIRE\",\n",
    "        \"Motifs\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"DATE Début\": \"date_debut_panne\",\n",
    "        \"HEURE Début\": \"heure_debut_panne\",\n",
    "        \"DATE Fin\": \"date_fin_panne\",\n",
    "        \"HEURE Fin\": \"heure_fin_panne\",\n",
    "        # \"Durée indispo (j) totale\": \"nb_jours_indispo\",\n",
    "        \"LIGNE\": \"ligne\",\n",
    "        \"STATION\": \"station\",\n",
    "        \"N° EQUIP.\": \"num_equip\",\n",
    "        \"COMMENTAIRE\": \"commentaire\",\n",
    "        \"Motifs\": \"motifs\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convertir les colonnes de date au format dd/mm/yyyy\n",
    "df[\"date_debut_panne\"] = pd.to_datetime(df[\"date_debut_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"date_fin_panne\"] = pd.to_datetime(df[\"date_fin_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "# Convertir les colonnes de temps au format HH:MM\n",
    "def convert_time_format(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        time_str = time_str.replace(\"h\", \":\").replace(\"H\", \":\")\n",
    "        if \":\" in time_str and len(time_str.split(\":\")[1]) == 0:\n",
    "            time_str += \"00\"\n",
    "    return time_str\n",
    "\n",
    "\n",
    "df[\"heure_debut_panne\"] = df[\"heure_debut_panne\"].apply(convert_time_format)\n",
    "df[\"heure_fin_panne\"] = df[\"heure_fin_panne\"].apply(convert_time_format)\n",
    "\n",
    "# Créer colonne type_equipement\n",
    "df[\"type_equipement\"] = (\n",
    "    df[\"num_equip\"].str.startswith(\"Asc\").map({True: \"ascenseur\", False: \"escalier\"})\n",
    ")\n",
    "\n",
    "# Créer une colonne annee_debut_panne\n",
    "df[\"annee_debut_panne\"] = pd.to_datetime(\n",
    "    df[\"date_debut_panne\"], format=\"%d/%m/%Y\"\n",
    ").dt.year\n",
    "\n",
    "\n",
    "# Calculer la durée d'indisponibilité en heures et jours\n",
    "def calculate_duration(row):\n",
    "    try:\n",
    "        start = pd.to_datetime(\n",
    "            f\"{row['date_debut_panne']} {row['heure_debut_panne']}\",\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "        )\n",
    "        end = pd.to_datetime(\n",
    "            f\"{row['date_fin_panne']} {row['heure_fin_panne']}\", format=\"%d/%m/%Y %H:%M\"\n",
    "        )\n",
    "        duration = (end - start).total_seconds() / 3600  # Convertir en heures\n",
    "        return duration, duration / 24  # Retourner heures et jours\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "df[[\"duree_indispo\", \"jour_indispo\"]] = df.apply(\n",
    "    calculate_duration, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Replace 'T1 ' with 'T1' in the 'ligne' column\n",
    "df[\"ligne\"] = df[\"ligne\"].str.replace(\"T1 \", \"T1\", regex=False)\n",
    "\n",
    "# Extract integers from the 'num_equip' column and create a new column 'id'\n",
    "df[\"id\"] = (\n",
    "    df[\"num_equip\"].str.extract(r\"(\\d+)\").astype(float)\n",
    ")  # Use raw string for regex\n",
    "\n",
    "df.to_csv(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_janv_25_clean.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "df.to_excel(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_janv_25_clean.xlsx\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c41ce1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VBO\\code\\asc_esc_consolide\\.conda\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(\n",
    "    os.getcwd(), \"points_marquants\", \"Points marquants maintenance Fevrier 2025.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(file_path, skiprows=1, sheet_name=\"Fevr 25\")\n",
    "\n",
    "# Filtrer les colonnes\n",
    "df = df[\n",
    "    [\n",
    "        \"DATE Début\",\n",
    "        \"HEURE Début\",\n",
    "        \"DATE Fin\",\n",
    "        \"HEURE Fin\",\n",
    "        # \"Durée indispo (j) totale\",\n",
    "        \"LIGNE\",\n",
    "        \"STATION\",\n",
    "        \"N° EQUIP.\",\n",
    "        \"COMMENTAIRE\",\n",
    "        \"Motifs\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"DATE Début\": \"date_debut_panne\",\n",
    "        \"HEURE Début\": \"heure_debut_panne\",\n",
    "        \"DATE Fin\": \"date_fin_panne\",\n",
    "        \"HEURE Fin\": \"heure_fin_panne\",\n",
    "        # \"Durée indispo (j) totale\": \"nb_jours_indispo\",\n",
    "        \"LIGNE\": \"ligne\",\n",
    "        \"STATION\": \"station\",\n",
    "        \"N° EQUIP.\": \"num_equip\",\n",
    "        \"COMMENTAIRE\": \"commentaire\",\n",
    "        \"Motifs\": \"motifs\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convertir les colonnes de date au format dd/mm/yyyy\n",
    "df[\"date_debut_panne\"] = pd.to_datetime(df[\"date_debut_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"date_fin_panne\"] = pd.to_datetime(df[\"date_fin_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "# Convertir les colonnes de temps au format HH:MM\n",
    "def convert_time_format(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        time_str = time_str.replace(\"h\", \":\").replace(\"H\", \":\")\n",
    "        if \":\" in time_str and len(time_str.split(\":\")[1]) == 0:\n",
    "            time_str += \"00\"\n",
    "    return time_str\n",
    "\n",
    "\n",
    "df[\"heure_debut_panne\"] = df[\"heure_debut_panne\"].apply(convert_time_format)\n",
    "df[\"heure_fin_panne\"] = df[\"heure_fin_panne\"].apply(convert_time_format)\n",
    "\n",
    "# Créer colonne type_equipement\n",
    "df[\"type_equipement\"] = (\n",
    "    df[\"num_equip\"].str.startswith(\"Asc\").map({True: \"ascenseur\", False: \"escalier\"})\n",
    ")\n",
    "\n",
    "# Créer une colonne annee_debut_panne\n",
    "df[\"annee_debut_panne\"] = pd.to_datetime(\n",
    "    df[\"date_debut_panne\"], format=\"%d/%m/%Y\"\n",
    ").dt.year\n",
    "\n",
    "\n",
    "# Calculer la durée d'indisponibilité en heures et jours\n",
    "def calculate_duration(row):\n",
    "    try:\n",
    "        start = pd.to_datetime(\n",
    "            f\"{row['date_debut_panne']} {row['heure_debut_panne']}\",\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "        )\n",
    "        end = pd.to_datetime(\n",
    "            f\"{row['date_fin_panne']} {row['heure_fin_panne']}\", format=\"%d/%m/%Y %H:%M\"\n",
    "        )\n",
    "        duration = (end - start).total_seconds() / 3600  # Convertir en heures\n",
    "        return duration, duration / 24  # Retourner heures et jours\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "df[[\"duree_indispo\", \"jour_indispo\"]] = df.apply(\n",
    "    calculate_duration, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Replace 'T1 ' with 'T1' in the 'ligne' column\n",
    "df[\"ligne\"] = df[\"ligne\"].str.replace(\"T1 \", \"T1\", regex=False)\n",
    "\n",
    "# Extract integers from the 'num_equip' column and create a new column 'id'\n",
    "df[\"id\"] = (\n",
    "    df[\"num_equip\"].str.extract(r\"(\\d+)\").astype(float)\n",
    ")  # Use raw string for regex\n",
    "\n",
    "df.to_csv(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_fev_25_clean.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "df.to_excel(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_fev_25_clean.xlsx\"),\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c81d058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\VBO\\code\\asc_esc_consolide\\.conda\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n",
      "c:\\Users\\VBO\\code\\asc_esc_consolide\\.conda\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:85: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(\n",
    "    os.getcwd(), \"points_marquants\", \"Points marquants maintenance Mars 2025.xlsx\"\n",
    ")\n",
    "\n",
    "df = pd.read_excel(file_path, skiprows=1)\n",
    "\n",
    "# Filtrer les colonnes\n",
    "df = df[\n",
    "    [\n",
    "        \"DATE Début\",\n",
    "        \"HEURE Début\",\n",
    "        \"DATE Fin\",\n",
    "        \"HEURE Fin\",\n",
    "        # \"Durée indispo (j) totale\",\n",
    "        \"LIGNE\",\n",
    "        \"STATION\",\n",
    "        \"N° EQUIP.\",\n",
    "        \"COMMENTAIRE\",\n",
    "        \"Motifs\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "df.rename(\n",
    "    columns={\n",
    "        \"DATE Début\": \"date_debut_panne\",\n",
    "        \"HEURE Début\": \"heure_debut_panne\",\n",
    "        \"DATE Fin\": \"date_fin_panne\",\n",
    "        \"HEURE Fin\": \"heure_fin_panne\",\n",
    "        # \"Durée indispo (j) totale\": \"nb_jours_indispo\",\n",
    "        \"LIGNE\": \"ligne\",\n",
    "        \"STATION\": \"station\",\n",
    "        \"N° EQUIP.\": \"num_equip\",\n",
    "        \"COMMENTAIRE\": \"commentaire\",\n",
    "        \"Motifs\": \"motifs\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Convertir les colonnes de date au format dd/mm/yyyy\n",
    "df[\"date_debut_panne\"] = pd.to_datetime(df[\"date_debut_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "df[\"date_fin_panne\"] = pd.to_datetime(df[\"date_fin_panne\"]).dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "\n",
    "# Convertir les colonnes de temps au format HH:MM\n",
    "def convert_time_format(time_str):\n",
    "    if isinstance(time_str, str):\n",
    "        time_str = time_str.replace(\"h\", \":\").replace(\"H\", \":\")\n",
    "        if \":\" in time_str and len(time_str.split(\":\")[1]) == 0:\n",
    "            time_str += \"00\"\n",
    "    return time_str\n",
    "\n",
    "\n",
    "df[\"heure_debut_panne\"] = df[\"heure_debut_panne\"].apply(convert_time_format)\n",
    "df[\"heure_fin_panne\"] = df[\"heure_fin_panne\"].apply(convert_time_format)\n",
    "\n",
    "# Créer colonne type_equipement\n",
    "df[\"type_equipement\"] = (\n",
    "    df[\"num_equip\"].str.startswith(\"Asc\").map({True: \"ascenseur\", False: \"escalier\"})\n",
    ")\n",
    "\n",
    "# Créer une colonne annee_debut_panne\n",
    "df[\"annee_debut_panne\"] = pd.to_datetime(\n",
    "    df[\"date_debut_panne\"], format=\"%d/%m/%Y\"\n",
    ").dt.year\n",
    "\n",
    "\n",
    "# Calculer la durée d'indisponibilité en heures et jours\n",
    "def calculate_duration(row):\n",
    "    try:\n",
    "        start = pd.to_datetime(\n",
    "            f\"{row['date_debut_panne']} {row['heure_debut_panne']}\",\n",
    "            format=\"%d/%m/%Y %H:%M\",\n",
    "        )\n",
    "        end = pd.to_datetime(\n",
    "            f\"{row['date_fin_panne']} {row['heure_fin_panne']}\", format=\"%d/%m/%Y %H:%M\"\n",
    "        )\n",
    "        duration = (end - start).total_seconds() / 3600  # Convertir en heures\n",
    "        return duration, duration / 24  # Retourner heures et jours\n",
    "    except Exception:\n",
    "        return None, None\n",
    "\n",
    "\n",
    "df[[\"duree_indispo\", \"jour_indispo\"]] = df.apply(\n",
    "    calculate_duration, axis=1, result_type=\"expand\"\n",
    ")\n",
    "\n",
    "# Replace 'T1 ' with 'T1' in the 'ligne' column\n",
    "df[\"ligne\"] = df[\"ligne\"].str.replace(\"T1 \", \"T1\", regex=False)\n",
    "\n",
    "# Extract integers from the 'num_equip' column and create a new column 'id'\n",
    "df[\"id\"] = (\n",
    "    df[\"num_equip\"].str.extract(r\"(\\d+)\").astype(float)\n",
    ")  # Use raw string for regex\n",
    "\n",
    "df.to_csv(\n",
    "    os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_mars_25_clean.csv\"),\n",
    "    sep=\";\",\n",
    "    index=False,\n",
    ")\n",
    "\n",
    "df.to_excel(os.path.join(os.getcwd(), \"points_marquants\", \"points_marquants_mars_25_clean.xlsx\"),index=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab681ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir le chemin vers le dossier contenant les fichiers Excel\n",
    "folder_path = os.path.join(os.getcwd(), \"points_marquants\")\n",
    "\n",
    "# Lire les fichiers CSV\n",
    "annee_24 = pd.read_csv(os.path.join(folder_path, 'points_marquants_24_clean.csv'), delimiter=';')\n",
    "janv_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_janv_25_clean.csv'), delimiter=';')\n",
    "fev_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_fev_25_clean.csv'), delimiter=';')\n",
    "mars_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_mars_25_clean.csv'), delimiter=';')\n",
    "\n",
    "# Fusionner les fichiers sur la colonne 'num_equip'\n",
    "merged_df = pd.concat([annee_24,fev_df, janv_df, mars_df])\n",
    "\n",
    "# Vérifier les doublons dans la colonne 'date_debut_panne'\n",
    "duplicates = merged_df.duplicated(subset=['date_debut_panne','num_equip'], keep=False)\n",
    "\n",
    "# Afficher les lignes avec des doublons\n",
    "duplicate_rows = merged_df[duplicates]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "641f426a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame avant la fusion des doublons :\n",
      "Nombre de lignes: 127\n",
      "\n",
      "Nombre de lignes après nettoyage initial: 124\n",
      "\n",
      "DataFrame après fusion (en gardant la date_fin_panne la plus récente) :\n",
      "Nombre de lignes: 103\n",
      "    date_debut_panne heure_debut_panne date_fin_panne heure_fin_panne ligne  \\\n",
      "0         01/01/2025             19:49     08/01/2025           12:53     D   \n",
      "1         01/02/2025             13:22     19/02/2025           10:00     B   \n",
      "2         02/01/2025             17:47     08/03/2025             NaN     D   \n",
      "3         02/02/2025             06:00     31/03/2025             NaN     A   \n",
      "4         03/02/2025            03:52      06/02/2025           09:35     D   \n",
      "..               ...               ...            ...             ...   ...   \n",
      "98        30/12/2024             19:27     03/01/2025           11:28     D   \n",
      "99        31/01/2025             18:44     03/02/2025           14:05     A   \n",
      "100       31/01/2025             07:04     11/02/2025            9:11     D   \n",
      "101       31/12/2024             08:53     24/01/2025           11:06     A   \n",
      "102       31/12/2024             11:23     28/01/2025           18:45     B   \n",
      "\n",
      "                   station  num_equip  \\\n",
      "0    Montplaisir Lumiere     Asc. 752   \n",
      "1              Jean Jaures   Asc. 461   \n",
      "2            Gorge de loup   Asc. 821   \n",
      "3                     Foch  Esc. 2302   \n",
      "4           Saxe gambetta   Esc. 4410   \n",
      "..                     ...        ...   \n",
      "98             Guillotière   Asc. 792   \n",
      "99               Bellecour   Asc. 264   \n",
      "100             Sans souci   Asc. 761   \n",
      "101           Gratte Ciel    Asc. 191   \n",
      "102                Debourg   Asc. 472   \n",
      "\n",
      "                                           commentaire motifs type_equipement  \\\n",
      "0    Remplacement coulisseaux - sabre porte\\nRéglag...    NaN       ascenseur   \n",
      "1                                         VF+MOTEUR HS  Panne       ascenseur   \n",
      "2    En attente passage serrurier pour devis - vant...  Usure       ascenseur   \n",
      "3    Reprise reglage plaque porte peigne + capteurs HS  Usure        escalier   \n",
      "4                           Reprise réglages plaque PP  Usure        escalier   \n",
      "..                                                 ...    ...             ...   \n",
      "98                                Probleme cellule HS   Panne       ascenseur   \n",
      "99                  reprise operateur de porte cabine   Panne       ascenseur   \n",
      "100                                       VF+MOTEUR HS  Panne       ascenseur   \n",
      "101                                Carte manoeuvre HS   Panne       ascenseur   \n",
      "102                    Poulie + cable de tractions hs   Usure       ascenseur   \n",
      "\n",
      "     annee_debut_panne  duree_indispo  jour_indispo      id  \n",
      "0               2025.0     161.066667      6.711111   752.0  \n",
      "1               2025.0     428.633333     17.859722   461.0  \n",
      "2               2025.0            NaN           NaN   821.0  \n",
      "3               2025.0            NaN           NaN  2302.0  \n",
      "4               2025.0            NaN           NaN  4410.0  \n",
      "..                 ...            ...           ...     ...  \n",
      "98              2024.0      88.016667      3.667361   792.0  \n",
      "99              2025.0      67.350000      2.806250   264.0  \n",
      "100             2025.0     266.116667     11.088194   761.0  \n",
      "101             2024.0     578.216667     24.092361   191.0  \n",
      "102             2024.0     679.366667     28.306944   472.0  \n",
      "\n",
      "[103 rows x 14 columns]\n",
      "\n",
      "Résultat sauvegardé dans : c:\\Users\\VBO\\code\\asc_esc_consolide\\points_marquants_fusionnes_recent.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Définir le chemin vers le dossier contenant les fichiers\n",
    "folder_path = os.path.join(os.getcwd(), \"points_marquants\")\n",
    "\n",
    "# Vérifier si le dossier existe\n",
    "if not os.path.isdir(folder_path):\n",
    "    print(f\"Erreur : Le dossier '{folder_path}' n'a pas été trouvé.\")\n",
    "    # Quitter ou gérer l'erreur comme vous le souhaitez\n",
    "    exit()\n",
    "\n",
    "# Lire les fichiers CSV (en s'assurant qu'ils existent)\n",
    "try:\n",
    "    annee_24 = pd.read_csv(os.path.join(folder_path, 'points_marquants_24_clean.csv'), delimiter=';')\n",
    "    janv_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_janv_25_clean.csv'), delimiter=';')\n",
    "    fev_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_fev_25_clean.csv'), delimiter=';')\n",
    "    mars_df = pd.read_csv(os.path.join(folder_path, 'points_marquants_mars_25_clean.csv'), delimiter=';')\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Erreur lors de la lecture d'un fichier CSV : {e}\")\n",
    "    # Quitter ou gérer l'erreur\n",
    "    exit()\n",
    "\n",
    "# Fusionner (concaténer) les fichiers de Janvier, Février, Mars\n",
    "# ignore_index=True réinitialise l'index du DataFrame résultant\n",
    "# merged_df = pd.concat([annee_24,fev_df, janv_df, mars_df], ignore_index=True)\n",
    "merged_df = pd.concat([janv_df, fev_df], ignore_index=True)\n",
    "\n",
    "print(\"DataFrame avant la fusion des doublons :\")\n",
    "print(f\"Nombre de lignes: {len(merged_df)}\")\n",
    "\n",
    "# 1. Nettoyer les données (optionnel mais recommandé)\n",
    "# Supprimer les lignes où les identifiants clés sont manquants\n",
    "merged_df.dropna(subset=['date_debut_panne', 'num_equip'], inplace=True)\n",
    "# Supprimer les lignes potentiellement vides ou mal formées (si toutes les colonnes sont NaN)\n",
    "merged_df.dropna(how='all', inplace=True)\n",
    "\n",
    "print(f\"\\nNombre de lignes après nettoyage initial: {len(merged_df)}\")\n",
    "\n",
    "\n",
    "# 2. Convertir 'date_fin_panne' en format datetime\n",
    "#    errors='coerce' transformera les dates invalides en NaT (Not a Time)\n",
    "#    Il est crucial de spécifier le format si ce n'est pas le format standard YYYY-MM-DD\n",
    "merged_df['date_fin_panne_dt'] = pd.to_datetime(merged_df['date_fin_panne'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Afficher les lignes où la conversion a échoué (si nécessaire)\n",
    "# print(\"\\nLignes avec date_fin_panne invalide (NaT) :\")\n",
    "# print(merged_df[merged_df['date_fin_panne_dt'].isna()])\n",
    "\n",
    "\n",
    "# 3. Trier les données\n",
    "#    Trier par les clés d'identification, puis par la date de fin (datetime) en ordre décroissant (plus récent en premier)\n",
    "#    na_position='last' met les NaT (dates invalides/manquantes) à la fin pour chaque groupe\n",
    "merged_df_sorted = merged_df.sort_values(\n",
    "    by=['date_debut_panne', 'num_equip', 'date_fin_panne_dt'],\n",
    "    ascending=[True, True, False], # Trie date_debut asc, num_equip asc, date_fin_dt desc\n",
    "    na_position='last' # Place les lignes sans date de fin valide à la fin\n",
    ")\n",
    "\n",
    "# 4. Supprimer les doublons en gardant la première ligne (qui est la plus récente après tri)\n",
    "#    subset indique les colonnes à utiliser pour identifier les doublons\n",
    "#    keep='first' conserve la première occurrence trouvée après le tri\n",
    "final_df = merged_df_sorted.drop_duplicates(\n",
    "    subset=['date_debut_panne', 'num_equip'],\n",
    "    keep='first'\n",
    ")\n",
    "\n",
    "# 5. Nettoyage final (optionnel)\n",
    "#    Supprimer la colonne de date temporaire si elle n'est plus nécessaire\n",
    "final_df = final_df.drop(columns=['date_fin_panne_dt'])\n",
    "#    Réinitialiser l'index si vous le souhaitez\n",
    "final_df = final_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# --- Fin : Logique de fusion ---\n",
    "\n",
    "# Afficher le résultat\n",
    "print(\"\\nDataFrame après fusion (en gardant la date_fin_panne la plus récente) :\")\n",
    "print(f\"Nombre de lignes: {len(final_df)}\")\n",
    "print(final_df)\n",
    "\n",
    "# Optionnel : Sauvegarder le résultat dans un nouveau fichier CSV\n",
    "try:\n",
    "    output_filename = 'points_marquants_fusionnes_recent.csv'\n",
    "    output_path = os.path.join(os.getcwd(), output_filename) # Sauvegarde dans le répertoire courant\n",
    "    final_df.to_csv(output_path, index=False, sep=';', encoding='utf-8-sig') # utf-8-sig pour compatibilité Excel\n",
    "    print(f\"\\nRésultat sauvegardé dans : {output_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nErreur lors de la sauvegarde du fichier : {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
